# RLPrompt with GRPO and Soft Q-Learning

This repository contains the code and experiments for the project RLPrompt with GRPO and Log-Likelihood Rewards by Joshua Bello (MIT).
The work extends RLPrompt (Deng et al., 2022) by comparing two reinforcement-learning–based prompt optimization algorithms—Soft Q-Learning and Group Relative Policy Optimization (GRPO)—under multiple reward types and evaluating their performance on BoolQ and GSM8K.
